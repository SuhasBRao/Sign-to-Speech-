{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd01aa32c3e39cce6b6a2a7f2e9227e06d8322f53ac0b3d2a2ea2c1a4485a851f90",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/suhas/GIT_HUB/Sign-to-Speech-/images'\n",
    "\n",
    "src = cv2.imread('roi.jpg', 1)\n",
    "blurred = cv2.GaussianBlur(src, (5, 5), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('blurred',blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "source": [
    "blurred_float = blurred.astype(np.float32) / 255.0\n",
    "edgeDetector = cv2.ximgproc.createStructuredEdgeDetection(\"model.yml\")\n",
    "edges = edgeDetector.detectEdges(blurred_float) * 255.0\n",
    "cv2.imwrite('C:/Users/suhas/GIT_HUB/Sign-to-Speech-/images/edge-raw.jpg', edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 159
    }
   ],
   "source": [
    "def filterOutSaltPepperNoise(edgeImg):\n",
    "    # Get rid of salt & pepper noise.\n",
    "    count = 0\n",
    "    lastMedian = edgeImg\n",
    "    median = cv2.medianBlur(edgeImg, 3)\n",
    "    while not np.array_equal(lastMedian, median):\n",
    "        # get those pixels that gets zeroed out\n",
    "        zeroed = np.invert(np.logical_and(median, edgeImg))\n",
    "        edgeImg[zeroed] = 0\n",
    "\n",
    "        count = count + 1\n",
    "        if count > 50:\n",
    "            break\n",
    "        lastMedian = median\n",
    "        median = cv2.medianBlur(edgeImg, 3)\n",
    "\n",
    "\n",
    "edges_8u = np.asarray(edges, np.uint8)\n",
    "filterOutSaltPepperNoise(edges_8u)\n",
    "cv2.imwrite('C:/Users/suhas/GIT_HUB/Sign-to-Speech-/images/edge.jpg', edges_8u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLargestContour(edgeImg):\n",
    "    contours, hierarchy = cv2.findContours(\n",
    "        edgeImg,\n",
    "        cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    \n",
    "    # From among them, find the contours with large surface area.\n",
    "    contoursWithArea = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        contoursWithArea.append([contour, area])\n",
    "\t\t\n",
    "    contoursWithArea.sort(key=lambda tupl: tupl[1], reverse=True)\n",
    "    largestContour = contoursWithArea[0][0]\n",
    "    return largestContour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "source": [
    "contour = findLargestContour(edges_8u)\n",
    "# Draw the contour on the original image\n",
    "contourImg = np.copy(src)\n",
    "cv2.drawContours(contourImg, [contour], 0, (0, 255, 0), 2, cv2.LINE_AA, maxLevel=1)\n",
    "cv2.imwrite('C:/Users/suhas/GIT_HUB/Sign-to-Speech-/images/contour.jpg', contourImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "mask = np.zeros_like(edges_8u)\n",
    "cv2.fillPoly(mask, [contour], 255)\n",
    "\n",
    "# calculate sure foreground area by dilating the mask\n",
    "mapFg = cv2.erode(mask, np.ones((5, 5), np.uint8), iterations=15)\n",
    "\n",
    "# mark inital mask as \"probably background\"\n",
    "# and mapFg as sure foreground\n",
    "trimap = np.copy(mask)\n",
    "trimap[mask == 0] = cv2.GC_BGD\n",
    "trimap[mask == 255] = cv2.GC_PR_BGD\n",
    "trimap[mapFg == 255] = cv2.GC_FGD\n",
    "\n",
    "# visualize trimap\n",
    "trimap_print = np.copy(trimap)\n",
    "trimap_print[trimap_print == cv2.GC_PR_BGD] = 135\n",
    "trimap_print[trimap_print == cv2.GC_FGD] = 255\n",
    "cv2.imwrite('C:/Users/suhas/GIT_HUB/Sign-to-Speech-/images/trimap.png', trimap_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 163
    }
   ],
   "source": [
    "bgdModel = np.zeros((1, 65), np.float64)\n",
    "fgdModel = np.zeros((1, 65), np.float64)\n",
    "rect = (0, 0, mask.shape[0] - 1, mask.shape[1] - 1)\n",
    "cv2.grabCut(src, trimap, rect, bgdModel, fgdModel, 12, cv2.GC_INIT_WITH_MASK)\n",
    "\n",
    "# create mask again\n",
    "mask2 = np.where(\n",
    "    (trimap == cv2.GC_FGD) | (trimap == cv2.GC_PR_FGD),\n",
    "    255,\n",
    "    0\n",
    ").astype('uint8')\n",
    "cv2.imwrite('C:/Users/suhas/GIT_HUB/Sign-to-Speech-/images/mask2.jpg', mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 164
    }
   ],
   "source": [
    "contour2 = findLargestContour(mask2)\n",
    "mask3 = np.zeros_like(mask2)\n",
    "cv2.fillPoly(mask3, [contour2], 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "source": [
    "mask3 = np.repeat(mask3[:, :, np.newaxis], 3, axis=2)\n",
    "mask4 = cv2.GaussianBlur(mask3, (7, 7), 0)\n",
    "alpha = mask4.astype(float) * 2 # making blend stronger\n",
    "alpha[mask3 > 0] = 255.0\n",
    "alpha[alpha > 255] = 255.0\n",
    "\n",
    "cv2.imshow('alpha',alpha)\n",
    "cv2.imshow('mask3',mask3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "foreground = np.copy(src).astype(float)\n",
    "foreground[mask4 == 0] = 0\n",
    "background = np.zeros_like(foreground, dtype=float) * 255.0\n",
    "\n",
    "cv2.imwrite('C:/Users/suhas/GIT_HUB/Sign-to-Speech-/images/foreground.png', foreground)\n",
    "cv2.imwrite('C:/Users/suhas/GIT_HUB/Sign-to-Speech-/images/background.png', background)\n",
    "cv2.imwrite('C:/Users/suhas/GIT_HUB/Sign-to-Speech-/images/alpha.png', alpha)\n",
    "\n",
    "# Normalize the alpha mask to keep intensity between 0 and 1\n",
    "alpha = alpha / 255.0\n",
    "# Multiply the foreground with the alpha matte\n",
    "foreground = cv2.multiply(alpha, foreground)\n",
    "# Multiply the background with ( 1 - alpha )\n",
    "background = cv2.multiply(1.0 - alpha, background)\n",
    "# Add the masked foreground and background.\n",
    "cutout = cv2.add(foreground, background)\n",
    "\n",
    "cv2.imwrite('cutout.jpg', cutout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}