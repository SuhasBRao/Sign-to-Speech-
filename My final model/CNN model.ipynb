{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd01aa32c3e39cce6b6a2a7f2e9227e06d8322f53ac0b3d2a2ea2c1a4485a851f90",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\suhas\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\nC:\\Users\\suhas\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\nC:\\Users\\suhas\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\nC:\\Users\\suhas\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\nC:\\Users\\suhas\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\nC:\\Users\\suhas\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os   # accessing folder paths\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import patoolib  # This is useful to extract zip files \n",
    "import cv2,glob \n",
    "import shutil   # this module is used to do file accessing operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {1:'1',2:'2',3:'3', 4:'4', 5:'5', 6:'6', 7:'7', 8:'8',\n",
    "           9:'9',10:'A',11:'B',12:'C',13:'D',14:'E',15:'F',16:'G',17:'H',18:'I',\n",
    "           19:'J',20:'K',21:'L',22:'M',23:'N',24:'O',25:'P',26:'Q',27:'R',28:'S',29:'T',30:'U',\n",
    "           31:'V',32:'W',33:'X',34:'Y',35:'Z'}\n",
    "words_data = {1:'All_The_Best', 2:'Hi!!', 3: 'I_Love_you', 4: 'No', 5:'Super!!', 6:'Yes'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating Folders for data. Please wait...\n",
      "A subdirectory or file G:\\gestures\\train\\1 already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\1 already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\2 already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\2 already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\3 already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\3 already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\4 already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\4 already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\5 already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\5 already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\6 already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\6 already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\7 already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\7 already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\8 already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\8 already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\9 already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\9 already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\A already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\A already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\B already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\B already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\C already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\C already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\D already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\D already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\E already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\E already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\F already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\F already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\G already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\G already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\H already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\H already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\I already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\I already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\J already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\J already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\K already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\K already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\L already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\L already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\M already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\M already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\N already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\N already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\O already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\O already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\P already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\P already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\Q already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\Q already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\R already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\R already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\S already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\S already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\T already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\T already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\U already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\U already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\V already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\V already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\W already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\W already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\X already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\X already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\Y already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\Y already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\Z already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\Z already exists.Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create directory for dataset\n",
    "# first create directories inthe name of class keys\n",
    "# You need to run this only once.\n",
    "print('Creating Folders for data. Please wait...')\n",
    "for dir_name in classes.values():\n",
    "    !mkdir {'G:\\\\gestures\\\\train\\\\' + dir_name}\n",
    "    !mkdir {'G:\\\\gestures\\\\test\\\\' + dir_name}\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating Folders for words data. Please wait....\n",
      "A subdirectory or file G:\\gestures\\words_data\\test\\All_The_Best already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\train\\All_The_Best already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\test\\Hi!! already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\train\\Hi!! already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\test\\I_Love_you already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\train\\I_Love_you already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\test\\No already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\train\\No already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\test\\Super!! already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\train\\Super!! already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\test\\Yes already exists.\n",
      "Done!!!\n",
      "A subdirectory or file G:\\gestures\\words_data\\train\\Yes already exists.\n"
     ]
    }
   ],
   "source": [
    "# creates data for words\n",
    "# RUN THIS ONLY ONCE \n",
    "print('Creating Folders for words data. Please wait....')\n",
    "for dir_name in words_data.values():\n",
    "    !mkdir {'G:\\\\gestures\\\\words_data\\\\test\\\\' + dir_name}\n",
    "    !mkdir {'G:\\\\gestures\\\\words_data\\\\train\\\\' + dir_name}\n",
    "    \n",
    "print('Done!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = None\n",
    "accumulated_weight = 0.7\n",
    "mask_color = (0.0,0.0,0.0)\n",
    "\n",
    "ROI_top = 100\n",
    "ROI_bottom = 300\n",
    "ROI_right = 300\n",
    "ROI_left = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to calculate accumulated_weights in the frame\n",
    "def cal_accum_avg(frame, accumulated_weight):\n",
    "\n",
    "    global background\n",
    "    \n",
    "    if background is None:\n",
    "        background = frame.copy().astype(\"float\")\n",
    "        return None\n",
    "\n",
    "    cv2.accumulateWeighted(frame, background, accumulated_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function segments the hand region found in the frame, if not found returns None.\n",
    "def segment_hand(frame, threshold=50):\n",
    "    global background\n",
    "    \n",
    "    diff = cv2.absdiff(background.astype(\"uint8\"), frame)\n",
    "\n",
    "    \n",
    "    _ , thresholded = cv2.threshold(diff, threshold, 255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    edges = cv2.Canny(thresholded, threshold1= 50, threshold2=250)\n",
    "    cv2.imshow('edges',thresholded)\n",
    "    \n",
    "     #Fetching contours in the frame (These contours can be of hand\n",
    "    #or any other object in foreground) â€¦\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(thresholded.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # If length of contours list = 0, means we didn't get any\n",
    "    #contours...\n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        # The largest external contour should be the hand\n",
    "        # contour_info = [(c, cv2.contourArea(c),) for c in contours[1]]\n",
    "\n",
    "        #cntrs, heirs = cv2.findContours(thresholded.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "        contour_info = [(c, cv2.contourArea(c),) for c in contours]\n",
    "        #for c in contours[1]:\n",
    "        #    contour_info.append((c,cv2.contourArea(c),))\n",
    "        \n",
    "        hand_segment_max_cont = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Returning the hand segment(max contour) and the\n",
    "  # thresholded image of hand and contour_info list\n",
    "    return (thresholded, hand_segment_max_cont, contour_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize tbase dir, train_dir, test_dir\n",
    "base_dir = 'G:\\\\gestures\\\\words_data\\\\'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir,'test')"
   ]
  },
  {
   "source": [
    "# Here we create the data_set for word recognition"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "#################################################\n",
      "Show sign for Hi!!!\n",
      "Creating data for Hi!!.....\n",
      "Done!\n",
      "#################################################\n",
      "Show sign for I_Love_you!\n",
      "Creating data for I_Love_you.....\n",
      "Done!\n",
      "#################################################\n",
      "Show sign for Yes!\n",
      "Creating data for Yes.....\n",
      "Done!\n",
      "#################################################\n",
      "Show sign for No!\n",
      "Creating data for No.....\n",
      "Done!\n",
      "#################################################\n",
      "Show sign for Super!!!\n",
      "Creating data for Super!!.....\n",
      "Done!\n",
      "#################################################\n",
      "Show sign for All_The_Best!\n",
      "Creating data for All_The_Best.....\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for element in words_data.values():\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    num_frames = 0\n",
    "    num_imgs_taken = 0\n",
    "    time.sleep(5)\n",
    "    print('#################################################')\n",
    "    print(f'Show sign for {element}!')\n",
    "\n",
    "    print(f'Creating data for {element}.....')\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "\n",
    "        # flipping the frame to prevent inverted image of captured frame...\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        frame_copy = frame.copy()\n",
    "\n",
    "        roi = frame[ROI_top:ROI_bottom, ROI_right:ROI_left]\n",
    "\n",
    "        gray_frame = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        gray_frame = cv2.GaussianBlur(gray_frame, (9, 9), 0)\n",
    "\n",
    "        if num_frames < 60:\n",
    "            cal_accum_avg(gray_frame, accumulated_weight)\n",
    "            if num_frames <= 59:\n",
    "                cv2.putText(frame_copy, \"FETCHING BACKGROUND...PLEASE WAIT\",\n",
    "                            (80, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "                \n",
    "        #Time to configure the hand specifically into the ROI...\n",
    "        elif num_frames <= 300: \n",
    "\n",
    "            hand = segment_hand(gray_frame)\n",
    "            cv2.putText(frame_copy, \"Adjust hand gesture for..\",\n",
    "                            (200, 400), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 1, (0,0,255), 2)\n",
    "                \n",
    "            if hand is not None:\n",
    "                \n",
    "                thresholded, hand_segment, contour_info = hand\n",
    "\n",
    "                # Draw contours around hand segment\n",
    "                cv2.drawContours(frame_copy, [hand_segment + (ROI_right,\n",
    "                ROI_top)], -1, (255, 0, 0),1)\n",
    "                \n",
    "                cv2.putText(frame_copy, str(num_frames)+\"For\" + str(element),\n",
    "                            (70, 45), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "                # Also display the thresholded image\n",
    "                cv2.imshow(\"Thresholded Hand Image\", thresholded)\n",
    "        \n",
    "        else: \n",
    "            \n",
    "            # Segmenting the hand region...\n",
    "            hand = segment_hand(gray_frame)\n",
    "            \n",
    "            # Checking if we are able to detect the hand...\n",
    "            if hand is not None:\n",
    "                \n",
    "                # unpack the thresholded img and the max_contour...\n",
    "                thresholded, hand_segment,contour_info = hand\n",
    "\n",
    "                # Drawing contours around hand segment\n",
    "                cv2.drawContours(frame_copy, [hand_segment + (ROI_right,\n",
    "                ROI_top)], -1, (255, 0, 0),1)\n",
    "                \n",
    "                cv2.putText(frame_copy, str(num_frames), (70, 45),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "                \n",
    "                cv2.putText(frame_copy,\"Adjust hand gesture for..\",(200, 400),cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 1,(0,0,                              255)                                                                                                                   , 2)\n",
    "                # Displaying the thresholded image\n",
    "                cv2.imshow(\"Thresholded Hand Image\", thresholded)\n",
    "                if num_imgs_taken <= 70:\n",
    "                    cv2.imwrite(\"G:\\\\gestures\\\\words_data\\\\test\\\\\"+str(element)+\"\\\\\" + str(num_imgs_taken) + '.jpg',                                   thresholded)\n",
    "                else:\n",
    "                    break\n",
    "                num_imgs_taken +=1\n",
    "            else:\n",
    "                cv2.putText(frame_copy, 'No hand detected...', (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "\n",
    "\n",
    "        # Drawing ROI on frame copy\n",
    "        cv2.rectangle(frame_copy, (ROI_left, ROI_top), (ROI_right,ROI_bottom), (255,128,0), 3)\n",
    "        \n",
    "        cv2.putText(frame_copy, \"Sign languge recognition_ _ _\", (10, 20), cv2.FONT_ITALIC, 0.5, (51,255,51), 1)\n",
    "        \n",
    "        # increment the number of frames for tracking\n",
    "        num_frames += 1\n",
    "\n",
    "        # Display the frame with segmented hand\n",
    "        cv2.imshow(\"Sign Detection\", frame_copy)\n",
    "\n",
    "        # Closing windows with Esc key...(any other key with ord can be used too.)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "    # Releasing the camera & destroying all the windows...\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "    \n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()"
   ]
  },
  {
   "source": [
    "# Create image data generators for test and train batches"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 4206 images belonging to 6 classes.\nFound 426 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# This cell creates data generators for train and test images.\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)                 .flow_from_directory(directory=train_dir, target_size=(64,64), class_mode='categorical', batch_size=10,shuffle=True)\n",
    "\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_dir, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)"
   ]
  },
  {
   "source": [
    "# Plot few images to check"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "{1: 'All_The_Best', 2: 'Hi!!', 3: 'I_Love_you', 4: 'No', 5: 'Super!!', 6: 'Yes'}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 3600x3600 with 10 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"362.52pt\" version=\"1.1\" viewBox=\"0 0 3592.8 362.52\" width=\"3592.8pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 362.52 \r\nL 3592.8 362.52 \r\nL 3592.8 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g clip-path=\"url(#pd4ddcc9f90)\">\r\n    <image height=\"349\" id=\"imageeb4399af98\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"7.2\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_2\">\r\n   <g clip-path=\"url(#p636d61ac34)\">\r\n    <image height=\"349\" id=\"image4d327607ce\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"366.12\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_3\">\r\n   <g clip-path=\"url(#p660bcb9524)\">\r\n    <image height=\"349\" id=\"image208eb96b50\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"725.04\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_4\">\r\n   <g clip-path=\"url(#p64f79a94c4)\">\r\n    <image height=\"349\" id=\"image61384902c1\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"1083.96\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_5\">\r\n   <g clip-path=\"url(#p9256a5ea79)\">\r\n    <image height=\"349\" id=\"imaged92a9669a1\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"1442.88\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_6\">\r\n   <g clip-path=\"url(#p92e0c9aa99)\">\r\n    <image height=\"349\" id=\"imagecd90b064a2\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"1801.8\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_7\">\r\n   <g clip-path=\"url(#pd8999298d3)\">\r\n    <image height=\"349\" id=\"image69005c28be\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"2160.72\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_8\">\r\n   <g clip-path=\"url(#pd499061074)\">\r\n    <image height=\"349\" id=\"image7d46345788\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"2519.64\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_9\">\r\n   <g clip-path=\"url(#p95f067295e)\">\r\n    <image height=\"349\" id=\"image1e31aeb3ef\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"2878.56\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_10\">\r\n   <g clip-path=\"url(#p173f286781)\">\r\n    <image height=\"349\" id=\"imagebad9507c6b\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"3237.48\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pd4ddcc9f90\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"7.2\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p636d61ac34\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"366.12\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p660bcb9524\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"725.04\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p64f79a94c4\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"1083.96\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p9256a5ea79\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"1442.88\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p92e0c9aa99\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"1801.8\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pd8999298d3\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"2160.72\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pd499061074\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"2519.64\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p95f067295e\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"2878.56\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p173f286781\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"3237.48\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Actual labels:\nHi!!  Hi!!  All_The_Best  No  I_Love_you  No  Hi!!  No  No  No  "
     ]
    }
   ],
   "source": [
    "imgs, labels = next(train_batches)\n",
    "print(words_data)\n",
    "#Plotting the images...\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(50,50))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotImages(imgs)\n",
    "print('Actual labels:')\n",
    "\n",
    "for i in labels:\n",
    "    print(words_data[np.argmax(i) + 1],end = '  ')\n"
   ]
  },
  {
   "source": [
    "# Initializing the SEQUENTIAL model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(6,activation =\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 62, 62, 32)        896       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 31, 31, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 15, 15, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 13, 13, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 4608)              0         \n_________________________________________________________________\ndense (Dense)                (None, 64)                294976    \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               8320      \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_3 (Dense)              (None, 6)                 774       \n=================================================================\nTotal params: 413,830\nTrainable params: 413,830\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/25\n",
      "421/421 [==============================] - 30s 71ms/step - loss: 2.2056e-07 - accuracy: 1.0000 - val_loss: 1.0143 - val_accuracy: 0.7934\n",
      "Epoch 2/25\n",
      "421/421 [==============================] - 32s 75ms/step - loss: 1.5872e-07 - accuracy: 1.0000 - val_loss: 1.0166 - val_accuracy: 0.7887\n",
      "Epoch 3/25\n",
      "421/421 [==============================] - 32s 75ms/step - loss: 1.2828e-07 - accuracy: 1.0000 - val_loss: 1.0112 - val_accuracy: 0.7887\n",
      "Epoch 4/25\n",
      "421/421 [==============================] - 32s 75ms/step - loss: 1.1941e-07 - accuracy: 1.0000 - val_loss: 1.0097 - val_accuracy: 0.7887\n",
      "Epoch 5/25\n",
      "421/421 [==============================] - 32s 75ms/step - loss: 1.1107e-07 - accuracy: 1.0000 - val_loss: 1.0108 - val_accuracy: 0.7887\n",
      "Epoch 6/25\n",
      "421/421 [==============================] - 32s 76ms/step - loss: 1.0334e-07 - accuracy: 1.0000 - val_loss: 1.0098 - val_accuracy: 0.7887\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(train_batches, epochs=25, callbacks=[reduce_lr, early_stop],  validation_data = test_batches)"
   ]
  },
  {
   "source": [
    "## Here we print the accuracy of the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss of 0.825911819934845; accuracy of 89.99999761581421%\n"
     ]
    }
   ],
   "source": [
    "# For getting next batch of testing imgs...\n",
    "imgs, labels = next(test_batches) \n",
    "\n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "\n",
    "#Once the model is fitted we save the model using model.save()  function.\n",
    "\n",
    "\n",
    "#model.save('best_model_dataflair3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('best_model.h5')"
   ]
  },
  {
   "source": [
    "# Prediction with model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('best_model.h5')\n",
    "background = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "num_frames =0\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    # flipping the frame to prevent inverted image of captured\n",
    "    #frame...\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    # ROI from the frame\n",
    "    roi = frame[ROI_top:ROI_bottom, ROI_right:ROI_left]\n",
    "\n",
    "    gray_frame = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (9, 9), 0)\n",
    "\n",
    "\n",
    "    if num_frames < 70:\n",
    "        \n",
    "        cal_accum_avg(gray_frame, accumulated_weight)\n",
    "        \n",
    "        cv2.putText(frame_copy, \"FETCHING BACKGROUND...PLEASE WAIT\",\n",
    "  (80, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "    \n",
    "    else: \n",
    "        # segmenting the hand region\n",
    "        hand = segment_hand(gray_frame)\n",
    "        \n",
    "        # Checking if we are able to detect the hand...\n",
    "        if hand is not None:\n",
    "            \n",
    "            thresholded, hand_segment,contour_info = hand\n",
    "\n",
    "            # Drawing contours around hand segment\n",
    "            cv2.drawContours(frame_copy, [hand_segment + (ROI_right,\n",
    "      ROI_top)], -1, (255, 0, 0),1)\n",
    "            \n",
    "            cv2.imshow(\"Thesholded Hand Image\", thresholded)\n",
    "            \n",
    "            thresholded = cv2.resize(thresholded, (64, 64))\n",
    "            thresholded = cv2.cvtColor(thresholded,\n",
    " cv2.COLOR_GRAY2RGB)\n",
    "            thresholded = np.reshape(thresholded,\n",
    "(1,thresholded.shape[0],thresholded.shape[1],3))\n",
    "            \n",
    "            pred = model.predict(thresholded)\n",
    "            cv2.putText(frame_copy, words_data[np.argmax(pred) + 1],\n",
    "(300, 45), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 1, (0,0,255), 2)\n",
    "            \n",
    "    # Draw ROI on frame_copy\n",
    "    cv2.rectangle(frame_copy, (ROI_left, ROI_top), (ROI_right,\n",
    "    ROI_bottom), (255,128,0), 3)\n",
    "\n",
    "    # incrementing the number of frames for tracking\n",
    "    num_frames += 1\n",
    "\n",
    "    # Display the frame with segmented hand\n",
    "    cv2.putText(frame_copy, \"Indian sign language recognition_ _ _\",\n",
    "    (10, 20), cv2.FONT_ITALIC, 0.5, (51,255,51), 1)\n",
    "    cv2.imshow(\"Sign Detection\", frame_copy)\n",
    "\n",
    "\n",
    "    # Close windows with Esc\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "# Release the camera and destroy all the windows\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()"
   ]
  }
 ]
}