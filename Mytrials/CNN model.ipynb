{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd01aa32c3e39cce6b6a2a7f2e9227e06d8322f53ac0b3d2a2ea2c1a4485a851f90",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os   # accessing folder paths\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import patoolib  # This is useful to extract zip files \n",
    "import cv2,glob \n",
    "import shutil   # this module is used to do file accessing operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {1:'1',2:'2',3:'3', 4:'4', 5:'5', 6:'6', 7:'7', 8:'8',\n",
    "           9:'9',10:'A',11:'B',12:'C',13:'D',14:'E',15:'F',16:'G',17:'H',18:'I',\n",
    "           19:'J',20:'K',21:'L',22:'M',23:'N',24:'O',25:'P',26:'Q',27:'R',28:'S',29:'T',30:'U',\n",
    "           31:'V',32:'W',33:'X',34:'Y',35:'Z'}\n",
    "words_data = {1:'All_The_Best', 2:'Hi!!', 3: 'I_Love_you', 4: 'No', 5:'Super!!', 6:'Yes'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating Folders for data. Please wait...\n",
      "A subdirectory or file G:\\gestures\\train\\1 already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\1 already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\2 already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\2 already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\3 already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\3 already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\4 already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\4 already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\5 already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\5 already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\6 already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\6 already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\7 already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\7 already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\8 already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\8 already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\9 already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\9 already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\A already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\A already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\B already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\B already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\C already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\C already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\D already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\D already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\E already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\E already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\F already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\F already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\G already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\G already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\H already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\H already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\I already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\I already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\J already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\J already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\K already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\K already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\L already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\L already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\M already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\M already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\N already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\N already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\O already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\O already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\P already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\P already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\Q already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\Q already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\R already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\R already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\S already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\S already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\T already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\T already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\U already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\U already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\V already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\V already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\W already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\W already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\X already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\X already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\Y already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\Y already exists.\n",
      "A subdirectory or file G:\\gestures\\train\\Z already exists.\n",
      "A subdirectory or file G:\\gestures\\test\\Z already exists.Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create directory for dataset\n",
    "# first create directories inthe name of class keys\n",
    "# You need to run this only once.\n",
    "print('Creating Folders for data. Please wait...')\n",
    "for dir_name in classes.values():\n",
    "    !mkdir {'G:\\\\gestures\\\\train\\\\' + dir_name}\n",
    "    !mkdir {'G:\\\\gestures\\\\test\\\\' + dir_name}\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating Folders for words data. Please wait....\n",
      "A subdirectory or file G:\\gestures\\words_data\\test\\All_The_Best already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\train\\All_The_Best already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\test\\Hi!! already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\train\\Hi!! already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\test\\I_Love_you already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\train\\I_Love_you already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\test\\No already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\train\\No already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\test\\Super!! already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\train\\Super!! already exists.\n",
      "A subdirectory or file G:\\gestures\\words_data\\test\\Yes already exists.\n",
      "Done!!!\n",
      "A subdirectory or file G:\\gestures\\words_data\\train\\Yes already exists.\n"
     ]
    }
   ],
   "source": [
    "# creates data for words\n",
    "# RUN THIS ONLY ONCE \n",
    "print('Creating Folders for words data. Please wait....')\n",
    "for dir_name in words_data.values():\n",
    "    !mkdir {'G:\\\\gestures\\\\words_data\\\\test\\\\' + dir_name}\n",
    "    !mkdir {'G:\\\\gestures\\\\words_data\\\\train\\\\' + dir_name}\n",
    "    \n",
    "print('Done!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = None\n",
    "accumulated_weight = 0.7\n",
    "mask_color = (0.0,0.0,0.0)\n",
    "\n",
    "ROI_top = 100\n",
    "ROI_bottom = 300\n",
    "ROI_right = 300\n",
    "ROI_left = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to calculate accumulated_weights in the frame\n",
    "def cal_accum_avg(frame, accumulated_weight):\n",
    "\n",
    "    global background\n",
    "    \n",
    "    if background is None:\n",
    "        background = frame.copy().astype(\"float\")\n",
    "        return None\n",
    "\n",
    "    cv2.accumulateWeighted(frame, background, accumulated_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function segments the hand region found in the frame, if not found returns None.\n",
    "def segment_hand(frame, threshold=50):\n",
    "    global background\n",
    "    \n",
    "    diff = cv2.absdiff(background.astype(\"uint8\"), frame)\n",
    "\n",
    "    \n",
    "    _ , thresholded = cv2.threshold(diff, threshold, 255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    edges = cv2.Canny(thresholded, threshold1= 50, threshold2=250)\n",
    "    cv2.imshow('edges',thresholded)\n",
    "    \n",
    "     #Fetching contours in the frame (These contours can be of hand\n",
    "    #or any other object in foreground) â€¦\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(thresholded.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # If length of contours list = 0, means we didn't get any\n",
    "    #contours...\n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        # The largest external contour should be the hand\n",
    "        # contour_info = [(c, cv2.contourArea(c),) for c in contours[1]]\n",
    "\n",
    "        #cntrs, heirs = cv2.findContours(thresholded.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "        contour_info = [(c, cv2.contourArea(c),) for c in contours]\n",
    "        #for c in contours[1]:\n",
    "        #    contour_info.append((c,cv2.contourArea(c),))\n",
    "        \n",
    "        hand_segment_max_cont = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Returning the hand segment(max contour) and the\n",
    "  # thresholded image of hand and contour_info list\n",
    "    return (thresholded, hand_segment_max_cont, contour_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize tbase dir, train_dir, test_dir\n",
    "base_dir = 'G:\\\\gestures\\\\words_data\\\\'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir,'test')"
   ]
  },
  {
   "source": [
    "# Here we create the data_set for word recognition"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "#################################################\n",
      "Show sign for Hi!!!\n",
      "Creating data for Hi!!.....\n",
      "Done!\n",
      "#################################################\n",
      "Show sign for I_Love_you!\n",
      "Creating data for I_Love_you.....\n",
      "Done!\n",
      "#################################################\n",
      "Show sign for Yes!\n",
      "Creating data for Yes.....\n",
      "Done!\n",
      "#################################################\n",
      "Show sign for No!\n",
      "Creating data for No.....\n",
      "Done!\n",
      "#################################################\n",
      "Show sign for Super!!!\n",
      "Creating data for Super!!.....\n",
      "Done!\n",
      "#################################################\n",
      "Show sign for All_The_Best!\n",
      "Creating data for All_The_Best.....\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for element in words_data.values():\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    num_frames = 0\n",
    "    num_imgs_taken = 0\n",
    "    time.sleep(5)\n",
    "    print('#################################################')\n",
    "    print(f'Show sign for {element}!')\n",
    "\n",
    "    print(f'Creating data for {element}.....')\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "\n",
    "        # flipping the frame to prevent inverted image of captured frame...\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        frame_copy = frame.copy()\n",
    "\n",
    "        roi = frame[ROI_top:ROI_bottom, ROI_right:ROI_left]\n",
    "\n",
    "        gray_frame = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        gray_frame = cv2.GaussianBlur(gray_frame, (9, 9), 0)\n",
    "\n",
    "        if num_frames < 60:\n",
    "            cal_accum_avg(gray_frame, accumulated_weight)\n",
    "            if num_frames <= 59:\n",
    "                cv2.putText(frame_copy, \"FETCHING BACKGROUND...PLEASE WAIT\",\n",
    "                            (80, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "                \n",
    "        #Time to configure the hand specifically into the ROI...\n",
    "        elif num_frames <= 300: \n",
    "\n",
    "            hand = segment_hand(gray_frame)\n",
    "            cv2.putText(frame_copy, \"Adjust hand gesture for..\",\n",
    "                            (200, 400), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 1, (0,0,255), 2)\n",
    "                \n",
    "            if hand is not None:\n",
    "                \n",
    "                thresholded, hand_segment, contour_info = hand\n",
    "\n",
    "                # Draw contours around hand segment\n",
    "                cv2.drawContours(frame_copy, [hand_segment + (ROI_right,\n",
    "                ROI_top)], -1, (255, 0, 0),1)\n",
    "                \n",
    "                cv2.putText(frame_copy, str(num_frames)+\"For\" + str(element),\n",
    "                            (70, 45), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "                # Also display the thresholded image\n",
    "                cv2.imshow(\"Thresholded Hand Image\", thresholded)\n",
    "        \n",
    "        else: \n",
    "            \n",
    "            # Segmenting the hand region...\n",
    "            hand = segment_hand(gray_frame)\n",
    "            \n",
    "            # Checking if we are able to detect the hand...\n",
    "            if hand is not None:\n",
    "                \n",
    "                # unpack the thresholded img and the max_contour...\n",
    "                thresholded, hand_segment,contour_info = hand\n",
    "\n",
    "                # Drawing contours around hand segment\n",
    "                cv2.drawContours(frame_copy, [hand_segment + (ROI_right,\n",
    "                ROI_top)], -1, (255, 0, 0),1)\n",
    "                \n",
    "                cv2.putText(frame_copy, str(num_frames), (70, 45),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "                \n",
    "                cv2.putText(frame_copy,\"Adjust hand gesture for..\",(200, 400),cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 1,(0,0,                              255)                                                                                                                   , 2)\n",
    "                # Displaying the thresholded image\n",
    "                cv2.imshow(\"Thresholded Hand Image\", thresholded)\n",
    "                if num_imgs_taken <= 70:\n",
    "                    cv2.imwrite(\"G:\\\\gestures\\\\words_data\\\\test\\\\\"+str(element)+\"\\\\\" + str(num_imgs_taken) + '.jpg',                                   thresholded)\n",
    "                else:\n",
    "                    break\n",
    "                num_imgs_taken +=1\n",
    "            else:\n",
    "                cv2.putText(frame_copy, 'No hand detected...', (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "\n",
    "\n",
    "        # Drawing ROI on frame copy\n",
    "        cv2.rectangle(frame_copy, (ROI_left, ROI_top), (ROI_right,ROI_bottom), (255,128,0), 3)\n",
    "        \n",
    "        cv2.putText(frame_copy, \"Sign languge recognition_ _ _\", (10, 20), cv2.FONT_ITALIC, 0.5, (51,255,51), 1)\n",
    "        \n",
    "        # increment the number of frames for tracking\n",
    "        num_frames += 1\n",
    "\n",
    "        # Display the frame with segmented hand\n",
    "        cv2.imshow(\"Sign Detection\", frame_copy)\n",
    "\n",
    "        # Closing windows with Esc key...(any other key with ord can be used too.)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "    # Releasing the camera & destroying all the windows...\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "    \n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()"
   ]
  },
  {
   "source": [
    "# Create image data generators for test and train batches"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 4206 images belonging to 6 classes.\nFound 426 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# This cell creates data generators for train and test images.\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)                 .flow_from_directory(directory=train_dir, target_size=(64,64), class_mode='categorical', batch_size=10,shuffle=True)\n",
    "\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_dir, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)"
   ]
  },
  {
   "source": [
    "# Plot few images to check"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "{1: 'All_The_Best', 2: 'Hi!!', 3: 'I_Love_you', 4: 'No', 5: 'Super!!', 6: 'Yes'}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 3600x3600 with 10 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"362.52pt\" version=\"1.1\" viewBox=\"0 0 3592.8 362.52\" width=\"3592.8pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 362.52 \r\nL 3592.8 362.52 \r\nL 3592.8 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g clip-path=\"url(#p20a5443bc6)\">\r\n    <image height=\"349\" id=\"imagece80fc5288\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"7.2\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_2\">\r\n   <g clip-path=\"url(#pf773f1bafd)\">\r\n    <image height=\"349\" id=\"image57566131a1\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"366.12\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_3\">\r\n   <g clip-path=\"url(#p007fb174ff)\">\r\n    <image height=\"349\" id=\"image7bde8f6324\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"725.04\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_4\">\r\n   <g clip-path=\"url(#p53c5fba7b6)\">\r\n    <image height=\"349\" id=\"imagea4516d242c\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"1083.96\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_5\">\r\n   <g clip-path=\"url(#p13c5e3eda6)\">\r\n    <image height=\"349\" id=\"image881cd1696d\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"1442.88\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_6\">\r\n   <g clip-path=\"url(#p21a634913c)\">\r\n    <image height=\"349\" id=\"imagea9c27fa0fa\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"1801.8\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_7\">\r\n   <g clip-path=\"url(#pc37a9a05da)\">\r\n    <image height=\"349\" id=\"image7e89ff28a0\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"2160.72\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_8\">\r\n   <g clip-path=\"url(#p08671a6752)\">\r\n    <image height=\"349\" id=\"imagef6d73e44c8\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"2519.64\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_9\">\r\n   <g clip-path=\"url(#p5b9b742353)\">\r\n    <image height=\"349\" id=\"image414581b884\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"2878.56\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_10\">\r\n   <g clip-path=\"url(#p58bb888c86)\">\r\n    <image height=\"349\" id=\"image8d81370da0\" transform=\"scale(1 -1)translate(0 -349)\" width=\"349\" x=\"3237.48\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.32\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p20a5443bc6\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"7.2\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pf773f1bafd\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"366.12\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p007fb174ff\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"725.04\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p53c5fba7b6\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"1083.96\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p13c5e3eda6\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"1442.88\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p21a634913c\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"1801.8\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pc37a9a05da\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"2160.72\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p08671a6752\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"2519.64\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p5b9b742353\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"2878.56\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p58bb888c86\">\r\n   <rect height=\"348.12\" width=\"348.12\" x=\"3237.48\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Actual labels:\nNo  Super!!  I_Love_you  No  No  No  All_The_Best  All_The_Best  I_Love_you  Hi!!  "
     ]
    }
   ],
   "source": [
    "imgs, labels = next(train_batches)\n",
    "print(words_data)\n",
    "#Plotting the images...\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(50,50))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotImages(imgs)\n",
    "print('Actual labels:')\n",
    "\n",
    "for i in labels:\n",
    "    print(words_data[np.argmax(i) + 1],end = '  ')\n"
   ]
  },
  {
   "source": [
    "# Initializing the SEQUENTIAL model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(6,activation =\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 62, 62, 32)        896       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 31, 31, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 15, 15, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 13, 13, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 4608)              0         \n_________________________________________________________________\ndense (Dense)                (None, 64)                294976    \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               8320      \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_3 (Dense)              (None, 6)                 774       \n=================================================================\nTotal params: 413,830\nTrainable params: 413,830\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/25\n",
      "421/421 [==============================] - 30s 71ms/step - loss: 2.2056e-07 - accuracy: 1.0000 - val_loss: 1.0143 - val_accuracy: 0.7934\n",
      "Epoch 2/25\n",
      "421/421 [==============================] - 32s 75ms/step - loss: 1.5872e-07 - accuracy: 1.0000 - val_loss: 1.0166 - val_accuracy: 0.7887\n",
      "Epoch 3/25\n",
      "421/421 [==============================] - 32s 75ms/step - loss: 1.2828e-07 - accuracy: 1.0000 - val_loss: 1.0112 - val_accuracy: 0.7887\n",
      "Epoch 4/25\n",
      "421/421 [==============================] - 32s 75ms/step - loss: 1.1941e-07 - accuracy: 1.0000 - val_loss: 1.0097 - val_accuracy: 0.7887\n",
      "Epoch 5/25\n",
      "421/421 [==============================] - 32s 75ms/step - loss: 1.1107e-07 - accuracy: 1.0000 - val_loss: 1.0108 - val_accuracy: 0.7887\n",
      "Epoch 6/25\n",
      "421/421 [==============================] - 32s 76ms/step - loss: 1.0334e-07 - accuracy: 1.0000 - val_loss: 1.0098 - val_accuracy: 0.7887\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(train_batches, epochs=25, callbacks=[reduce_lr, early_stop],  validation_data = test_batches)"
   ]
  },
  {
   "source": [
    "## Here we print the accuracy of the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss of 0.825911819934845; accuracy of 89.99999761581421%\n"
     ]
    }
   ],
   "source": [
    "# For getting next batch of testing imgs...\n",
    "imgs, labels = next(test_batches) \n",
    "\n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "\n",
    "#Once the model is fitted we save the model using model.save()  function.\n",
    "\n",
    "\n",
    "#model.save('best_model_dataflair3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('best_model.h5')"
   ]
  },
  {
   "source": [
    "# Prediction with model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('best_model.h5')\n",
    "background = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "num_frames =0\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    # flipping the frame to prevent inverted image of captured\n",
    "    #frame...\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    # ROI from the frame\n",
    "    roi = frame[ROI_top:ROI_bottom, ROI_right:ROI_left]\n",
    "\n",
    "    gray_frame = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (9, 9), 0)\n",
    "\n",
    "\n",
    "    if num_frames < 70:\n",
    "        \n",
    "        cal_accum_avg(gray_frame, accumulated_weight)\n",
    "        \n",
    "        cv2.putText(frame_copy, \"FETCHING BACKGROUND...PLEASE WAIT\",\n",
    "  (80, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "    \n",
    "    else: \n",
    "        # segmenting the hand region\n",
    "        hand = segment_hand(gray_frame)\n",
    "        \n",
    "        # Checking if we are able to detect the hand...\n",
    "        if hand is not None:\n",
    "            \n",
    "            thresholded, hand_segment,contour_info = hand\n",
    "\n",
    "            # Drawing contours around hand segment\n",
    "            cv2.drawContours(frame_copy, [hand_segment + (ROI_right,\n",
    "      ROI_top)], -1, (255, 0, 0),1)\n",
    "            \n",
    "            cv2.imshow(\"Thesholded Hand Image\", thresholded)\n",
    "            \n",
    "            thresholded = cv2.resize(thresholded, (64, 64))\n",
    "            thresholded = cv2.cvtColor(thresholded,\n",
    " cv2.COLOR_GRAY2RGB)\n",
    "            thresholded = np.reshape(thresholded,\n",
    "(1,thresholded.shape[0],thresholded.shape[1],3))\n",
    "            \n",
    "            pred = model.predict(thresholded)\n",
    "            cv2.putText(frame_copy, words_data[np.argmax(pred) + 1],\n",
    "(300, 45), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 1, (0,0,255), 2)\n",
    "            \n",
    "    # Draw ROI on frame_copy\n",
    "    cv2.rectangle(frame_copy, (ROI_left, ROI_top), (ROI_right,\n",
    "    ROI_bottom), (255,128,0), 3)\n",
    "\n",
    "    # incrementing the number of frames for tracking\n",
    "    num_frames += 1\n",
    "\n",
    "    # Display the frame with segmented hand\n",
    "    cv2.putText(frame_copy, \"Indian sign language recognition_ _ _\",\n",
    "    (10, 20), cv2.FONT_ITALIC, 0.5, (51,255,51), 1)\n",
    "    cv2.imshow(\"Sign Detection\", frame_copy)\n",
    "\n",
    "\n",
    "    # Close windows with Esc\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "# Release the camera and destroy all the windows\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary module which is Opencv\n",
    "import cv2 as cv\n",
    "# Creating a cascade classifier object by passing the required path containg the haar cascades .xml files\n",
    "face_cascade = cv.CascadeClassifier('hand.xml')\n",
    "\n",
    "# Checks whether the path and cascade classifier was loaded correctly\n",
    "test = face_cascade.load('palm.xml')\n",
    "\n",
    "print(test)\n",
    "\n",
    "if not face_cascade.empty():\t# if the casecade object is not empty then continue with the processing\n",
    "\t#print(face_cascade.empty())\n",
    "\timg = cv.VideoCapture(0)\t# Captures the video from the webcam/to load a video pass the video path\n",
    "\twhile True:\n",
    "\t\tret,frame = img.read()\t# retrieves frames one by one from the webcam\n",
    "\t\t# ret is a flag which indicates whether the frame was retreived correctly\n",
    "\t\tframe = cv.flip(frame, 1)\n",
    "\t\tgray = cv.cvtColor(frame,cv.COLOR_BGR2GRAY)\t\t# converts the rgb/bgr frame to gray for processing purposes \n",
    "\t\t\n",
    "\t\tblured = cv.GaussianBlur(gray,(5,5),cv.BORDER_DEFAULT)\t# blurs the gray image to improve detection\n",
    "\t\t\n",
    "\t\tfaces = face_cascade.detectMultiScale(blured,1.2,9)\t\t# returns the detected faces as rectangle co-ordinates\n",
    "\n",
    "\t\tfor (x,y,w,h) in faces:\n",
    "\t\t\tcv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\t\t# Draws retangle on the detected faces\n",
    "\t\t\n",
    "\t\tcv.imshow('Hand Detection',frame)\t\t\t\n",
    "\n",
    "\t\tk = cv.waitKey(20) & 0xff\n",
    "\t\tif k==27:\n",
    "\t\t\tbreak\n",
    "\timg.release()\n",
    "\tcv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}